<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Mojo: Training-Free Image Editing via Skip Connection Modulation</title>
  <link rel="icon" href="./static/images/favicon.svg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Mojo: Training-Free Image Editing via Skip Connection Modulation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Peiang_Zhao1">Peiang Zhao</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="" target="_blank">Han Li</a><sup>1</sup>,
                  <span class="author-block">
                    <a href="" target="_blank">Ruiyang Jin</a><sup>1</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=8eNm2GMAAAAJ&hl=en">S. Kevin Zhou</a><sup>1,2&dagger;</sup>,
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>University of Science and Technology of China,</span>
                    <span class="author-block"><sup>2</sup>Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS),<br>Institute of Computing Technology</span>
                    <!-- <span class="author-block"></span> -->
                    <span class="email-cntrb"><small><br><sup>&dagger; Indicates Corresponding Author</sup></small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://github.com/momopusheen/Mojo/blob/main/Mojo_Training-Free_Image_Editing_via_Skip_Connection_Modulation.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href=" " target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>


            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- <section class="hero teaser">
  </div>
  Abstract
  </div>
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">

        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->


<!-- Introduction image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/mojo_teaser.png" alt="Intro Image">
      <h2 class="subtitle">
        Variance maps across channels of skip connection features within the U-Net for the text prompt "A superhero in New York City" at the 15-th timestep of the diffusion process. 
        These skip connection features exhibit high variance in regions corresponding to the structure of the generated image.
      </h2>
    </div>
  </div>
</section>
<!-- End introduction Image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Text-to-image diffusion models have recently garnered significant attention for their ability to create diverse and realistic visual contents. However, adapting these models for real image editing remains challenging. Existing text-guided image
            editing methods either struggle to achieve effective editing while maintaining the overall image structure, or require extensive fine-tuning, making them impractical
            for many applications. 
          </p>
          <p>
            To address these challenges, we introduce Mojo, a novel
            training-free approach for effective and structure-preserving image editing. Mojo
            incorporates two innovative techniques: Skip Connection Modulation (SCM) and
            Cross Image Self-Attention (CISA). SCM leverages the potential of skip connections within the diffusion U-Net. By modulating skip connection features during
            image editing process, it retains the source image structure while facilitating
            successful modifications. CISA further enhances the quality of edited images by
            improving fine-grained visual details through self-attention transfer. 
          </p>
          <p>
            Extensive experiments show that Mojo outperforms existing image editing methods, delivering
            superior results in versatile image editing scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Framework -->
<section class="hero teaser is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="margin-bottom: 60px;"></div> <!-- 或者使用其他高度 -->
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Framework</h2>
        <div style="margin-bottom: 40px;"></div> <!-- 或者使用其他高度 -->
      </div>
      <img src="static/images/mojo_pipeline.png" alt="Methods">
      <h2 class="subtitle">
        We first invert the source image to its corresponding latent encoding via DDIM inversion and extract skip connection features during this process. Subsequently, we
        simultaneously reconstruct the source image and perform image editing using our proposed Skip Connection Modulation (SCM) and Cross-Image Self-Attention (CISA).
      </h2>
    </div>
  </div>
</section>
<!-- End Framework -->


<!-- Framework -->
<section class="hero teaser is-light">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="margin-bottom: 60px;"></div> <!-- 或者使用其他高度 -->
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Visual comparisons with competing methods</h2>
        <div style="margin-bottom: 40px;"></div> <!-- 或者使用其他高度 -->
      </div>
      <img src="static/images/mojo_comp.png" alt="Methods">
      <h2 class="subtitle has-text-centered">
        Mojo strikes a good balance between faithful editing and image structure.
      </h2>
    </div>
  </div>
</section>
<!-- End Framework -->


<!-- Variation image-->
<section class="section hero is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Visual variations across various editing scenarios</h2>
    </div>
    <div class="container is-max-desktop">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/mojo_face.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Manipulation on facial attributes.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/mojo_var1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Image editing results.
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/mojo_var2.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Image editing results.
    </h2>
  </div>
  </div>
</div>
</div>
</section>
<!-- End variation image -->

<!-- Framework -->
<section class="hero teaser is-light">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="margin-bottom: 60px;"></div> <!-- 或者使用其他高度 -->
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Quantitative comparisons</h2>
        <div style="margin-bottom: 40px;"></div> <!-- 或者使用其他高度 -->
      </div>
      <img src="static/images/mojo_res.png" alt="Methods">
      <h2 class="subtitle">
        Quantitative comparisons on Wild-TI2I, ImageNet-R-TI2I and ImageNet-Real benchmarks. 
        Mojo strikes a good balance between faithful editing and image structure.
      </h2>
    </div>
  </div>
</section>
<!-- End Framework -->





<!-- Image carousel -->

<!-- End image carousel -->




<!-- Youtube video -->

<!-- End youtube video -->


<!-- Video carousel -->

<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
